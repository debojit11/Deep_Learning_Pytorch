{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPcbdLwZ7/Mw1JqcLZA8Ltt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debojit11/Deep_Learning_Pytorch/blob/main/practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75MmalotBTn1"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar (0D Tensor)\n",
        "scalar = torch.tensor(5)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtgjzC26BwJW",
        "outputId": "c4af94e1-db1b-4926-b510-850acd0650af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector (1D Tensor)\n",
        "vector = torch.tensor([1,2,3])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64SVH4mBB2H9",
        "outputId": "558d2c79-a68f-4776-ae8a-04252d7ebda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix (2D Tensor)\n",
        "matrix = torch.tensor([[1,2], [3,4]])\n",
        "matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4cdODq4B8tG",
        "outputId": "382e4b76-539e-4419-d932-e256e6510587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D Tensor\n",
        "tensor3d = torch.tensor([[[1,2], [3,4], [5,6]]])\n",
        "tensor3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6cgdxpbCEdO",
        "outputId": "9ede4d23-bd3e-4de7-bdd3-51552b1d5b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2],\n",
              "         [3, 4],\n",
              "         [5, 6]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1,2,3])\n",
        "b = torch.tensor([4,5,6])"
      ],
      "metadata": {
        "id": "4I6sr2JbCVU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#addition\n",
        "a+b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bw2aRxvCqNb",
        "outputId": "0037fac0-2dd4-4d36-e810-8e1d66edaab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 7, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subtraction\n",
        "a-b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqI_TxPlCsIK",
        "outputId": "c3c37ad2-f06f-40be-ee96-8ffcdc2480b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3, -3, -3])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiplication\n",
        "a*b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbY_sbVaCvmL",
        "outputId": "4fb1298d-a941-403e-a4e6-9a3c3aaa031e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4, 10, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# division\n",
        "a/b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEzEsxvODChM",
        "outputId": "039a78cf-b02c-473d-cf96-e2adb244f94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2500, 0.4000, 0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A= torch.tensor([[1,2], [3,4]])\n",
        "B= torch.tensor([[5,6], [7,8]])"
      ],
      "metadata": {
        "id": "LTnhx_mGDGy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix multiplication\n",
        "torch.mm(A,B) # or use A @ B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0pDn5GuDsAB",
        "outputId": "49dae6d0-adaf-4430-de9c-af7020d8747c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19, 22],\n",
              "        [43, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0, requires_grad=True) # Enable autograd"
      ],
      "metadata": {
        "id": "s_4r55CqDzHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2    # y = x^2\n",
        "y.backward()  # Compute gradient, dy/dx\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZNHqG-EEm1-",
        "outputId": "0e60ef7e-3659-4889-e8d4-f65e6b7da4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0, requires_grad=True) # Enable autograd\n",
        "y = x**2    # y = x^2\n",
        "z = 3*y + 2  # z = 3y + 2\n",
        "# Compute gradient\n",
        "z.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "3weH4JUuExsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83419400-5ccf-47c5-c845-85b0e4d90002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(18.)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.tensor([[1,2,3], [4,5,6]])\n",
        "i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEw_ewQnGdth",
        "outputId": "9b3be853-3ba5-4d40-da20-90784ca3a31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose the matrix\n",
        "i_T = i.T     # or A.transpose(0, 1)\n",
        "i_T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTdYBqFMGuL0",
        "outputId": "c807e878-8810-4d9b-8e94-2cccbab27de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If you have a 3D tensor (batch of matrices), use .permute() instead.**"
      ],
      "metadata": {
        "id": "QU1BoYdQHHTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise**"
      ],
      "metadata": {
        "id": "DEh7JWp8Ho0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   **Create a 4x4 tensor with random values. Find its transpose.**\n",
        "\n",
        "\n",
        "2.   **Compute the gradient of f(x)= 4x^3 + 3x^2 - 5x + 2 at x=2 using PyTorch’s autograd**\n",
        "\n",
        "\n",
        "3.   **Multiply a 2x3 tensor with a 3x2 tensor and print the result.**\n"
      ],
      "metadata": {
        "id": "wUqxoLJ2HtOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.rand(4,4)\n",
        "tensor1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3jAqEwBHBw2",
        "outputId": "318c4a02-99c5-4718-d48a-05407616763a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1458, 0.5640, 0.6568, 0.3524],\n",
              "        [0.1482, 0.2194, 0.2557, 0.5214],\n",
              "        [0.0874, 0.5163, 0.3376, 0.7359],\n",
              "        [0.1704, 0.6663, 0.4750, 0.8656]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abCM19vuLjGT",
        "outputId": "205ea8a6-35c9-4502-a620-05aa8dd10362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1458, 0.1482, 0.0874, 0.1704],\n",
              "        [0.5640, 0.2194, 0.5163, 0.6663],\n",
              "        [0.6568, 0.2557, 0.3376, 0.4750],\n",
              "        [0.3524, 0.5214, 0.7359, 0.8656]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j = torch.tensor(2.0, requires_grad=True)\n",
        "y = 4*(j**3) + 3*(j**2) - 5*j + 2\n",
        "y.backward()\n",
        "j.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaQaWFyvIevP",
        "outputId": "127fd0c2-a0ce-4a48-db8f-107c3c00a4e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(55.)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor23 = torch.randint(0,10,(2,3))\n",
        "tensor23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9qkMdzHJTdc",
        "outputId": "6e7851ca-40bc-4465-ec19-a7dcebf595c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9, 7, 2],\n",
              "        [0, 6, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor32 = torch.randint(0,10,(3,2))\n",
        "tensor32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5kANzxhKwX1",
        "outputId": "86f3161f-5488-43c8-925c-a41508e68f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4, 0],\n",
              "        [1, 7],\n",
              "        [9, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mm(tensor23, tensor32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_FloysPKzbd",
        "outputId": "5b48a254-f1ef-44d1-a8e6-f11c7b8faa0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[61, 61],\n",
              "        [51, 72]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(5.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "Yv6leCXPJI6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = 3*(a**3) - 4*(a**2) + 2*a - 1\n",
        "b.backward()\n",
        "a.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bshdPArJKEau",
        "outputId": "8247e13f-0075-41f0-c637-9d9e55bd2370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(187.)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**==========================================================================================================================================================================================================================**"
      ],
      "metadata": {
        "id": "8bBlrFGZcDSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "NdYcqE6QcJrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the network\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(3,4)  # 3 inputs → 4 neurons\n",
        "    self.fc2 = nn.Linear(4,1)  # 4 → 1 output\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.fc1(x))  # activation after first layer\n",
        "    x = torch.sigmoid(self.fc2(x))  # sigmoid at output\n",
        "    return x"
      ],
      "metadata": {
        "id": "R1FXPZWrcuZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize network\n",
        "model = SimpleNN()"
      ],
      "metadata": {
        "id": "fB56SRPcd60S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy input\n",
        "x = torch.tensor([1.0, 2.0, 3.0])"
      ],
      "metadata": {
        "id": "Aceb7c4ud-KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass\n",
        "output = model(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPuNv5KWeGi7",
        "outputId": "a2265444-7c4c-4e24-a9d1-e4e9e1f86c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5063], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the network\n",
        "class basicNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(basicNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(2,5)  # 2 inputs → 5 neurons\n",
        "    self.fc2 = nn.Linear(5,1)  # 5 → 1 output\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.fc1(x))  # activation after first layer\n",
        "    x = torch.sigmoid(self.fc2(x))  # sigmoid at output\n",
        "    return x"
      ],
      "metadata": {
        "id": "cscDrcsxeNRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = basicNN()"
      ],
      "metadata": {
        "id": "8M5v9oKZeq1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, -1.0])\n",
        "output = model1(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbrsVMPVet9X",
        "outputId": "0fc764e3-85e1-4249-abc8-058cb4d5a0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6467], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model1.parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk2jK1HRe6v_",
        "outputId": "55a5259a-604a-474f-8349-a2c185b5573e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.parameters of basicNN(\n",
            "  (fc1): Linear(in_features=2, out_features=5, bias=True)\n",
            "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**==========================================================================================================================================================================================================================**"
      ],
      "metadata": {
        "id": "BQELCaIsplJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "WaKA1uEApotw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy dataset (inputs and binary labels)\n",
        "X = torch.tensor([[1.0, 2.0],\n",
        "                  [2.0, -1.0],\n",
        "                  [-1.0, -2.0],\n",
        "                  [-2.0, 1.0]])\n",
        "y = torch.tensor([[1.0], [1.0], [0.0], [0.0]])"
      ],
      "metadata": {
        "id": "lqykLNrDpvdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model\n",
        "class BinaryClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(2, 10) # hidden layer was five earlier, this is for exercise\n",
        "    self.fc2 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    return torch.sigmoid(self.fc2(x))"
      ],
      "metadata": {
        "id": "DyLkmZbfqa8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BinaryClassifier()"
      ],
      "metadata": {
        "id": "jYoR1JLvrI6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss & Optimizer\n",
        "criterion = nn.MSELoss() # was BCELoss() earlier, this is for exercise\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "cr63WZ8lrKyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(10):\n",
        "  # forward pass\n",
        "  outputs = model(X)\n",
        "  loss = criterion(outputs, y)\n",
        "\n",
        "  # backward pass\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f\"Epoch : [{epoch}],  Loss : {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-c1BZ9nrPaz",
        "outputId": "31b86d82-9a44-4444-8fbd-eed13800d78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : [0],  Loss : 0.2698\n",
            "Epoch : [1],  Loss : 0.2615\n",
            "Epoch : [2],  Loss : 0.2535\n",
            "Epoch : [3],  Loss : 0.2457\n",
            "Epoch : [4],  Loss : 0.2381\n",
            "Epoch : [5],  Loss : 0.2306\n",
            "Epoch : [6],  Loss : 0.2232\n",
            "Epoch : [7],  Loss : 0.2159\n",
            "Epoch : [8],  Loss : 0.2091\n",
            "Epoch : [9],  Loss : 0.2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the loss going down at each epoch is very low"
      ],
      "metadata": {
        "id": "QyR1gCrmtjG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final predictions\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(model(X).detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzmTXfXYsPWi",
        "outputId": "fc54e26a-697d-4ccc-91c3-97fe51683127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Predictions:\n",
            "tensor([[0.6222],\n",
            "        [0.4930],\n",
            "        [0.4873],\n",
            "        [0.3813]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**==========================================================================================================================================================================================================================**"
      ],
      "metadata": {
        "id": "5uMdRwIR0Hca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "370Pd8AB0HD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1)  # Output: 8x28x28\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Output: 8x14x14\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, 1, 1)  # Output: 16x14x14 → pool → 16x7x7\n",
        "        self.fc1 = nn.Linear(16*7*7, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)  # 10 classes for digits\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Conv + ReLU + Pool\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*7*7)  # flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qKyKetEG0RG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "aeaTyPRc0gYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiExda0Z0kqF",
        "outputId": "a5adafad-b9dc-4031-be2b-43fda1aa852d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 14.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 500kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.86MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.24MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "FYhkTW5R0nA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "    for images, labels in train_loader:\n",
        "        output = model(images)\n",
        "        loss = loss_fn(output, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch [{epoch+1}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAT3NBfS0qXn",
        "outputId": "794c4818-ccb0-45b4-c37e-4a3021644a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Loss: 0.0299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**==========================================================================================================================================================================================================================**"
      ],
      "metadata": {
        "id": "4SLdG_418Paj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "ktYVRunJ0sIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "64ce6399-5426-4482-b823-91147ed96e40"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dde3c70c-fd85-468f-9fd0-93e924f1a467\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dde3c70c-fd85-468f-9fd0-93e924f1a467\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving archive.zip to archive.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile(\"archive.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"handwritten_dataset\")"
      ],
      "metadata": {
        "id": "cDCe_lI08VDd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List files to make sure everything's extracted properly\n",
        "os.listdir(\"handwritten_dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li5qagcl_Jug",
        "outputId": "92da91b5-02c2-4157-dbe8-c9269532d1a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "S3HnL3Vj_VtR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "GdEN1w73_okr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"handwritten_dataset/dataset\""
      ],
      "metadata": {
        "id": "RV_Cl7gJ_tSA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize((28,28)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "])"
      ],
      "metadata": {
        "id": "iTSgiHOM_1kD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "JEm8IYvz_2Ny"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Classes: {dataset.classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoAGwOJ-Auf5",
        "outputId": "fc363569-910b-4c4b-d946-9556e5b3d032"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'J', 'K', 'L', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'a', 'aA', 'b', 'bb', 'c', 'd', 'dd', 'e', 'eE', 'f', 'g', 'gg', 'h', 'hh', 'i', 'll', 'm', 'n', 'nn', 'o', 'p', 'q', 'qQ', 'r', 'rR', 'tT', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(dataloader))\n",
        "\n",
        "# Show first image\n",
        "plt.imshow(images[0].squeeze(), cmap=\"gray\")\n",
        "plt.title(f\"Label: {dataset.classes[labels[0]]}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "XxeWwP3ZAzKQ",
        "outputId": "cc9912db-2443-4f57-c273-30c5439a42fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZ04rlYBBNYC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}